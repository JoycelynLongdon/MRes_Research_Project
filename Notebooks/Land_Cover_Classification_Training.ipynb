{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landcover Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources: \n",
    "- https://blog.gishub.org/earth-engine-tutorial-32-machine-learning-with-earth-engine-supervised-classification\n",
    "- https://geohackweek.github.io/GoogleEarthEngine/05-classify-imagery/\n",
    "- https://ceholden.github.io/open-geo-tutorial/python/chapter_5_classification.html\n",
    "- GEE Documentation\n",
    "\n",
    "#### Steps:\n",
    "1. Collect training data. Assemble features which have a property that stores the known class label and properties storing numeric values for the predictors.\n",
    "2. Instantiate a classifier. Set its parameters if necessary.\n",
    "3. Train the classifier using the training data.\n",
    "4. Classify an image or feature collection.\n",
    "5. Estimate classification error with independent validation data.\n",
    "\n",
    "The training data is a `FeatureCollection` with a property storing the class label and properties storing predictor variables. Class labels should be consecutive, integers starting from 0. If necessary, use remap() to convert class values to consecutive integers. The predictors should be numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "from geemap import *\n",
    "import json\n",
    "from geemap import geojson_to_ee, ee_to_geojson\n",
    "from ipyleaflet import GeoJSON\n",
    "import os\n",
    "import sklearn\n",
    "# !pip install geemap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15d7ca6556f4b378aecdc15c1f2896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region data to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15d7ca6556f4b378aecdc15c1f2896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=1614465.046875, center=[37.75379999999999, -122.44390000000001], controls=(WidgetControl(options=['…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "point = ee.Geometry.Point(-122.4439, 37.7538)\n",
    "\n",
    "#making a cloud free Landsat 8 Surface Reflectance Composite\n",
    "image = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterBounds(point).filterDate('2016-01-01', '2016-12-31').sort('CLOUD_COVER').first()\n",
    "\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 3000,\n",
    "    'bands': ['B4', 'B3', 'B2'] #True Colour Composite\n",
    "}\n",
    "\n",
    "\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image, vis_params, \"Landsat-8\")\n",
    "Map\n",
    "#Map.addLayer(aoi, \"Mai_Ndombe\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask the image for clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15d7ca6556f4b378aecdc15c1f2896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.75379999999999, -122.44390000000001], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "#cloud mask\n",
    "def cloudMask(image):\n",
    "  #Bits 3 and 5 are cloud shadow and cloud, respectively.\n",
    "    cloudShadowBitMask = (1 << 3);\n",
    "    cloudsBitMask = (1 << 5);\n",
    "    #Get the pixel QA band.\n",
    "    qa = image.select('pixel_qa');\n",
    "    #Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0));\n",
    "    return image.updateMask(mask);\n",
    "\n",
    "image = cloudMask(image)\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image, vis_params, \"Landsat-8_Masked\")\n",
    "Map\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-11-18'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.get('CLOUD_COVER').getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training dataset\n",
    "\n",
    "There are several ways you can create a region for generating the training dataset.\n",
    "\n",
    "- Draw a shape (e.g., rectangle) on the map and the use `region = Map.user_roi`\n",
    "- Define a geometry, such as `region = ee.Geometry.Rectangle([-122.6003, 37.4831, -121.8036, 37.8288])`\n",
    "- Create a buffer zone around a point, such as `region = ee.Geometry.Point([-122.4439, 37.7538]).buffer(10000)`\n",
    "- If you don't define a region, it will use the image footprint by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = Map.user_roi\n",
    "# region = ee.Geometry.Rectangle([-122.6003, 37.4831, -121.8036, 37.8288])\n",
    "region = ee.Geometry.Point([-122.4439, 37.7538]).buffer(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [USGS National Land Cover Database (NLCD)](https://developers.google.com/earth-engine/datasets/catalog/USGS_NLCD) will be used to create label dataset for training\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/7QoRXxu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15d7ca6556f4b378aecdc15c1f2896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=25521.0, center=[38.25112269630296, -122.51678466796876], controls=(WidgetControl(options=['positio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlcd = ee.Image('USGS/NLCD/NLCD2016').select('landcover').clip(image.geometry()) #pre-defined data from an Earth Engine table asset\n",
    "#remapping the LULC categories to new values ranging from 0–19 to make \n",
    "#visualizations consistent across products later in the script.\n",
    "\n",
    "#remapping class values for nlcd data\n",
    "class_values = nlcd.get('landcover_class_values')\n",
    "class_values_remap = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "nlcd = nlcd.remap(class_values,\n",
    "         class_values_remap).rename('Landcover_Class')\n",
    "\n",
    "#import the colour palette of the nlcd data\n",
    "classColours = (\n",
    "  '476ba1','d1defa','decaca','d99482','ee0000',\n",
    "  'ab0000','b3aea3','68ab63','1c6330','b5ca8f',\n",
    "  'a68c30','ccba7d','e3e3c2','caca78','99c247',\n",
    "  '78ae94','dcd93d','ab7028','bad9eb','70a3ba'\n",
    "    )\n",
    "\n",
    "Map.addLayer(nlcd, {'min':0, 'max':19, 'palette':classColours}, 'NLCD')\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training dataset.\n",
    "'''points = nlcd.sample(**{\n",
    "    'region': image.geometry(), #The region to sample from. If unspecified, uses the image's whole footprint.\n",
    "    'scale': 30, #A nominal scale in meters of the projection to sample in.\n",
    "    'numPixels': 5000, #The approximate number of pixels to sample.\n",
    "    'seed': 0, #A randomization seed to use for subsampling.\n",
    "    'geometries': True  # If true, adds the center of the sampled pixel as the geometry property of the output \n",
    "                        #feature. Otherwise, geometries will be omitted (saving memory).Set this to False to \n",
    "                        #ignore geometries\n",
    "})\n",
    "'''\n",
    "sample = nlcd.sample(**{\n",
    "    'region': image.geometry(), #The region to sample from. If unspecified, uses the image's whole footprint.\n",
    "    'scale': 30, #A nominal scale in meters of the projection to sample in.\n",
    "    'numPixels': 50000, #The approximate number of pixels to sample.\n",
    "    'seed': 0, #A randomization seed to use for subsampling.\n",
    "    'geometries': True  # If true, adds the center of the sampled pixel as the geometry property of the output \n",
    "                        #feature. Otherwise, geometries will be omitted (saving memory).Set this to False to \n",
    "                        #ignore geometries\n",
    "})\n",
    "\n",
    "\n",
    "#The randomColumn() method will add a column of uniform random\n",
    "#numbers in a column named 'random' by default.\n",
    "sample = sample.randomColumn();\n",
    "\n",
    "split = 0.7;  #Roughly 70% training, 30% testing.\n",
    "training = sample.filter(ee.Filter.lt('random', split))\n",
    "validation = sample.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "Map.addLayer(training, {}, 'Training')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.first().getInfo()) #Returns the first entry from a given collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the training data as csv\n",
    "geemap.ee_to_csv(training, 'lc_training_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the validation data as csv\n",
    "geemap.ee_to_csv(validation, 'lc_validation_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier\n",
    "\n",
    "Here we complete supervised classification using the RandomForest ensemble decision tree algorithm by [Leo Breiman and Adele Cutler](https://link.springer.com/article/10.1023/A:1010933404324).\n",
    "\n",
    "The RandomForest algorithm is popular in the field of remote sensing, and is quite fast compared to some other machine learning approaches (e.g., SVM can be quite computationally intensive). It isn't necessarily the best but provides great first step into the world of machine learning for classification and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "\n",
    "\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'Landcover_Class'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "training = image.select(bands).sampleRegions(**{\n",
    "  'collection': training,\n",
    "  'properties': [label],\n",
    "  'scale': 30\n",
    "})\n",
    "\n",
    "# Train a Random Forest classifier with 10 decision trees (will employ hyperparameter testing outside of notebook)\n",
    "classifier = ee.Classifier.smileRandomForest(100).train(training,label,bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the data as csv\n",
    "geemap.ee_to_csv(training, 'trained_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "classified = image.select(bands).classify(classifier)\n",
    "\n",
    "# Display the clusters with random colors.\n",
    "Map.addLayer(classified.randomVisualizer(), {}, 'classfied')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render categorical map\n",
    "\n",
    "To render a categorical map, we can set two image properties: `landcover_class_values` and `landcover_class_palette`. We can use the same style as the NLCD so that it is easy to compare the two maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classValues = class_values_remap \n",
    "classValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_palette = nlcd.get('landcover_class_palette').getInfo()\n",
    "class_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = classified.set('classification_class_values', classValues)\n",
    "landcover = landcover.set('classification_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(landcover, {}, 'Land Cover Map')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Change layer opacity:')\n",
    "cluster_layer = Map.layers[-1]\n",
    "cluster_layer.interact(opacity=(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a legend to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Map.add_legend(builtin_legend='NLCD')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tif file\n",
    "geemap.ee_export_image(landcover, 'Land_Cover_Classification.tif', scale=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess The Accuracy\n",
    "\n",
    "A confusion matrix is used here to compare two different image grids. We will be using it primarily to compute overall accuracy between the model and the validation layer, but confusion matrices also provide explicit information about which LULC classes were classified incorrectly; not just if pixels were classified incorrectly, but what LULC they were incorrectly classified as. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a confusion matrix representing resubstitution accuracy.\n",
    "train_conf_matrix = classifier.confusionMatrix()\n",
    "train_conf_matrix.getInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the overall train accuracy\n",
    "train_accuracy = train_conf_matrix.accuracy()\n",
    "train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy estimated from training data is an overestimate because the random forest is “fit” to the training data.\n",
    "\n",
    "To get validation accuracy, we classify the validation data.\n",
    "\n",
    "We want to ensure that the training samples are uncorrelated with the evaluation samples. This might result from spatial autocorrelation of the phenomenon being predicted. One way to exclude samples that might be correlated in this manner is to remove samples that are within some distance to any other sample(s). This can be accomplished with a spatial join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on NLCD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get validation points.\n",
    "validation = image.select(bands).sampleRegions(**{\n",
    "  'collection': validation,\n",
    "  'properties': [label],\n",
    "  'scale': 30\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated = validation.classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the data as csv\n",
    "geemap.ee_to_csv(validated, 'validated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a confusion matrix representing resubstitution accuracy.\n",
    "#errorMatrix computes a 2D error matrix for a collection by comparing two columns \n",
    "#of a collection: one containing the actual values, and one containing predicted values.\n",
    "test_conf_matrix = validated.errorMatrix('Landcover_Class', 'classification')\n",
    "test_conf_matrix.getInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the overall test accuracy\n",
    "test_accuracy = test_conf_matrix.accuracy()\n",
    "test_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not perform too well on data it hasn't seen before. Hyperparameter testing will need to be performed to improve this performance.\n",
    "\n",
    "Already just adjusting from 10 to 100 trees moved the accuracy from 0.58 to 0.62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation on AOI (Mai Ndombe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-Up Data for first time period for AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#clip image to only include aoi region\n",
    "file_path = os.path.abspath('/Users/joycelynlongdon/Desktop/Cambridge/CambridgeCoding/MRES/GEE_examples/sample.json')\n",
    "\n",
    "with open(file_path) as f:\n",
    "    aoi_poly = json.load(f)\n",
    "\n",
    "geometry = ee.FeatureCollection(aoi_poly).first().geometry()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cloud free Landsat 8 Surface Reflectance Composite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "point = ee.Geometry.Point(18.3300, -2.00)\n",
    "#pointBuffer = point.buffer(100000)\n",
    "image_aoi = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2016-06-01', '2016-08-31').sort('CLOUD_COVER').first().clip(geometry)\n",
    "\n",
    "def cloudMask(image):\n",
    "  #Bits 3 and 5 are cloud shadow and cloud, respectively.\n",
    "    cloudShadowBitMask = (1 << 3);\n",
    "    cloudsBitMask = (1 << 5);\n",
    "    #Get the pixel QA band.\n",
    "    qa = image_aoi.select('pixel_qa');\n",
    "    #Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0));\n",
    "    return image_aoi.updateMask(mask);\n",
    "\n",
    "\n",
    "image_aoi = cloudMask(image_aoi)\n",
    "#taking out any remaining cloud cover with the bitmask QA band\n",
    "#qa = image.select('pixel_qa')\n",
    "#cloudMask = qa.bitwiseAnd(1<<5).eq(0)\n",
    "#.and(qa.bitwiseAnd(1<<3).eq(0))\n",
    "#masked = image.updateMask(cloudMask).clip(bounds)\n",
    "\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 3000,\n",
    "    'bands': ['B5', 'B4', 'B3']\n",
    "}\n",
    "\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image_aoi, vis_params, \"Landsat-8\")\n",
    "Map\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aoi_class = image_aoi.classify(classifier)\n",
    "geemap.ee_to_csv(aoi_class, 'aoi_data.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Map.addLayer(aoi_class, vis_params, \"AOI Classification\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
